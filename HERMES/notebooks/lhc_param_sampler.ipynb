{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latin Hypercube Sampling\n",
    "Due to the parameter space being large, we utilize Latin Hypercube to sample the parameter space to a managable level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import qmc\n",
    "import astropy.units as u\n",
    "import astropy.constants as c\n",
    "\n",
    "# 10 Sampled parameters\n",
    "# 3 more that get attached from stellar temperature\n",
    "\n",
    "T_eff = [3000, 7000] # K\n",
    "Rad_p = [0.4, 2.0] # R_E\n",
    "M_p = [0.4, 10] # M_E\n",
    "T_eq = [100, 1000] # K\n",
    "CH4 = [-13, -0.5] # log10(CH4)\n",
    "H2O = [-13, -0.5] # log10(H2O)\n",
    "CO2 = [-13, -0.5] # log10(CO2)\n",
    "O2 = [-13, -0.5] # log10(O2)\n",
    "O3 = [-13, -0.5] # log10(O3)\n",
    "N20 = [-13, -0.5] # log10(N2O)\n",
    "\n",
    "# Create the Bounds parameter\n",
    "bounds = np.array([T_eff, Rad_p, M_p, T_eq, CH4, H2O, CO2, O2, O3, N20]).T\n",
    "\n",
    "# Create the Latin Hypercube Sampling object\n",
    "sampler = qmc.LatinHypercube(d=bounds.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "n_samples = 1000000\n",
    "samples = sampler.random(n_samples)\n",
    "\n",
    "# Scale samples to the bounds\n",
    "scaled_samples = qmc.scale(samples, bounds[0], bounds[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to get the stellar radius, log(g), and metallicity from actual stellar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the stellar hosts data\n",
    "stellar_hosts = pd.read_csv('../data/STELLARHOSTS.csv', skiprows=20)\n",
    "\n",
    "# Some preprocessing\n",
    "# if there is no mass or log g, remove the row\n",
    "stellar_hosts = stellar_hosts[stellar_hosts['st_logg'].notna() | (stellar_hosts['st_mass'].notna() & stellar_hosts['st_rad'].notna())]\n",
    "\n",
    "# Only beteen 3000 and 7000 K\n",
    "stellar_hosts = stellar_hosts[(stellar_hosts['st_teff'] > 3000) & (stellar_hosts['st_teff'] < 7000)]\n",
    "\n",
    "# if there is no log g, calculate it from the mass and radius\n",
    "stellar_hosts['st_logg'] = stellar_hosts['st_logg'].fillna(\n",
    "    np.log10(((stellar_hosts['st_mass'] * c.M_sun.cgs * c.G.cgs) / (stellar_hosts['st_rad'] * c.R_sun.cgs)**2))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:57<00:00, 17325.76it/s]\n"
     ]
    }
   ],
   "source": [
    "teff_sampled = scaled_samples[:, 0]\n",
    "rads_sampled = np.zeros_like(teff_sampled)\n",
    "logg_sampled = np.zeros_like(teff_sampled)\n",
    "met_sampled = np.zeros_like(teff_sampled)\n",
    "from tqdm import tqdm\n",
    "# Find the closest stellar host for each sampled temperature\n",
    "for i in tqdm(range(len(teff_sampled))):\n",
    "    # Find the closest stellar host\n",
    "    idx = (np.abs(stellar_hosts['st_teff'] - teff_sampled[i])).idxmin()\n",
    "    rads_sampled[i] = stellar_hosts['st_rad'][idx]\n",
    "    logg_sampled[i] = stellar_hosts['st_logg'][idx]\n",
    "    met_sampled[i] = stellar_hosts['st_met'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the stellar parameters into the sampled data\n",
    "scaled_samples = np.insert(scaled_samples, 1, met_sampled, axis=1)\n",
    "scaled_samples = np.insert(scaled_samples, 1, logg_sampled, axis=1)\n",
    "scaled_samples = np.insert(scaled_samples, 1, rads_sampled, axis=1)\n",
    "\n",
    "# Add an array at the first column with the index of the sample\n",
    "# Want to be able to label the samples when training\n",
    "scaled_samples = np.insert(scaled_samples, 0, np.arange(n_samples), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the samples to a CSV file\n",
    "data_formats = ['%d'] + ['%.3f'] * (scaled_samples.shape[1] - 1)\n",
    "np.savetxt('../data/sampled_parameters.csv', scaled_samples, delimiter=',', header='indx,T_eff,Rad_s,logg,met,Rad_p,M_p,T_eq,CH4,H2O,CO2,O2,O3,N20', fmt=data_formats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
